{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qmHOWW0SoNXM"
   },
   "source": [
    "## 1. SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 279403,
     "status": "ok",
     "timestamp": 1758896227092,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "SdkpgMl2-b_2",
    "outputId": "ac4c31bb-9a21-4257-b1a1-1f3ba4e9e8f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (10704179, 119)\n",
      "Test shape: (1527298, 119)\n",
      "데이터 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# import zipfile\n",
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # zip_path = '/content/drive/MyDrive/2025_dacon_toss/data/toss_datasets.zip'\n",
    "# extract_path = './data' # 데이터 존재 경로\n",
    "\n",
    "# # os.makedirs(extract_path, exist_ok=True) # 경로 없으면 생성\n",
    "\n",
    "# # with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "# #     zip_ref.extractall(extract_path)\n",
    "\n",
    "# # print(f\"'{zip_path}' 압축 해제 완료. 해제 경로: '{extract_path}'\")\n",
    "\n",
    "# # Load the train.parquet file\n",
    "# train = pd.read_parquet(os.path.join(extract_path, \"train.parquet\"), engine=\"pyarrow\")\n",
    "# test = pd.read_parquet(os.path.join(extract_path, \"test.parquet\"), engine=\"pyarrow\")\n",
    "\n",
    "# print(f\"Train shape: {train.shape}\")\n",
    "# print(f\"Test shape: {test.shape}\")\n",
    "# print(\"데이터 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5345,
     "status": "ok",
     "timestamp": 1758896441690,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "Gm4qykhunvBB",
    "outputId": "625cabd9-6866-47c2-b1c0-44fe4ac3850e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "CFG = {\n",
    "    'BATCH_SIZE': 1024,\n",
    "    'EPOCHS': 5,\n",
    "    'LEARNING_RATE': 1e-3,\n",
    "    'SEED': 42\n",
    "}\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGK9aUXeoiR-"
   },
   "source": [
    "## 2. DATA LOADED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1758896441695,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "uCd2bIHhoUyI",
    "outputId": "404d50a6-6ca3-4b52-9aa3-0304bf420566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 시작\n",
      "Train shape: (10704179, 119)\n",
      "Test shape: (1527298, 119)\n",
      "데이터 로드 완료\n",
      "Num features: 113 | Cat features: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"데이터 로드 시작\")\n",
    "train = pd.read_parquet(\"../data/train.parquet\", engine=\"pyarrow\") \n",
    "test = pd.read_parquet(\"../data/test.parquet\", engine=\"pyarrow\")\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"데이터 로드 완료\")\n",
    "\n",
    "target_col = \"clicked\"\n",
    "seq_col = \"seq\"\n",
    "FEATURE_EXCLUDE = {target_col, seq_col, \"ID\"}\n",
    "feature_cols = [c for c in train.columns if c not in FEATURE_EXCLUDE]\n",
    "\n",
    "cat_cols = [\"gender\", \"age_group\", \"inventory_id\", \"l_feat_14\"]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "print(f\"Num features: {len(num_cols)} | Cat features: {len(cat_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TflAeV4UolRe"
   },
   "source": [
    "## 3. ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28133,
     "status": "ok",
     "timestamp": 1758896486025,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "eSuF-onNok7h",
    "outputId": "ca740dbf-16fb-43c0-c572-40d53d443c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender unique categories: 3\n",
      "age_group unique categories: 9\n",
      "inventory_id unique categories: 18\n",
      "l_feat_14 unique categories: 3286\n"
     ]
    }
   ],
   "source": [
    "def encode_categoricals(train_df, test_df, cat_cols):\n",
    "    encoders = {}\n",
    "    for col in cat_cols:\n",
    "        le = LabelEncoder()\n",
    "        all_values = pd.concat([train_df[col], test_df[col]], axis=0).astype(str).fillna(\"UNK\")\n",
    "        le.fit(all_values)\n",
    "        train_df[col] = le.transform(train_df[col].astype(str).fillna(\"UNK\"))\n",
    "        test_df[col]  = le.transform(test_df[col].astype(str).fillna(\"UNK\"))\n",
    "        encoders[col] = le\n",
    "        print(f\"{col} unique categories: {len(le.classes_)}\")\n",
    "    return train_df, test_df, encoders\n",
    "\n",
    "train, test, cat_encoders = encode_categoricals(train, test, cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cXWj66Dqos80"
   },
   "source": [
    "## 4. MODULE DEFINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMlFduBuotiw"
   },
   "outputs": [],
   "source": [
    "class ClickDataset(Dataset):\n",
    "    def __init__(self, df, num_cols, cat_cols, seq_col, target_col=None, has_target=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.num_cols = num_cols\n",
    "        self.cat_cols = cat_cols\n",
    "        self.seq_col = seq_col\n",
    "        self.target_col = target_col\n",
    "        self.has_target = has_target\n",
    "        self.num_X = self.df[self.num_cols].astype(float).fillna(0).values\n",
    "        self.cat_X = self.df[self.cat_cols].astype(int).values\n",
    "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
    "        if self.has_target:\n",
    "            self.y = self.df[self.target_col].astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        num_x = torch.tensor(self.num_X[idx], dtype=torch.float)\n",
    "        cat_x = torch.tensor(self.cat_X[idx], dtype=torch.long)\n",
    "        s = self.seq_strings[idx]\n",
    "        if s:\n",
    "            arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
    "        else:\n",
    "            arr = np.array([0.0], dtype=np.float32)\n",
    "        seq = torch.from_numpy(arr)\n",
    "        if self.has_target:\n",
    "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
    "            return num_x, cat_x, seq, y\n",
    "        else:\n",
    "            return num_x, cat_x, seq\n",
    "\n",
    "def collate_fn_train(batch):\n",
    "    num_x, cat_x, seqs, ys = zip(*batch)\n",
    "    num_x = torch.stack(num_x)\n",
    "    cat_x = torch.stack(cat_x)\n",
    "    ys = torch.stack(ys)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
    "    return num_x, cat_x, seqs_padded, seq_lengths, ys\n",
    "\n",
    "def collate_fn_infer(batch):\n",
    "    num_x, cat_x, seqs = zip(*batch)\n",
    "    num_x = torch.stack(num_x)\n",
    "    cat_x = torch.stack(cat_x)\n",
    "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
    "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
    "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
    "    return num_x, cat_x, seqs_padded, seq_lengths\n",
    "\n",
    "class CrossNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(input_dim, 1, bias=True) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x = x0\n",
    "        for w in self.layers:\n",
    "            x = x0 * w(x) + x\n",
    "        return x\n",
    "\n",
    "class WideDeepCTR(nn.Module):\n",
    "    def __init__(self, num_features, cat_cardinalities, emb_dim=16, lstm_hidden=64,\n",
    "                 hidden_units=[512,256,128], dropout=[0.1,0.2,0.3]):\n",
    "        super().__init__()\n",
    "        self.emb_layers = nn.ModuleList([\n",
    "            nn.Embedding(cardinality, emb_dim) for cardinality in cat_cardinalities\n",
    "        ])\n",
    "        cat_input_dim = emb_dim * len(cat_cardinalities)\n",
    "        self.bn_num = nn.BatchNorm1d(num_features)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden,\n",
    "                            num_layers=2, batch_first=True, bidirectional=True)\n",
    "        seq_out_dim = lstm_hidden * 2\n",
    "        self.cross = CrossNetwork(num_features + cat_input_dim + seq_out_dim, num_layers=2)\n",
    "        input_dim = num_features + cat_input_dim + seq_out_dim\n",
    "        layers = []\n",
    "        for i, h in enumerate(hidden_units):\n",
    "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout[i % len(dropout)])]\n",
    "            input_dim = h\n",
    "        layers += [nn.Linear(input_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, num_x, cat_x, seqs, seq_lengths):\n",
    "        num_x = self.bn_num(num_x)\n",
    "        cat_embs = [emb(cat_x[:, i]) for i, emb in enumerate(self.emb_layers)]\n",
    "        cat_feat = torch.cat(cat_embs, dim=1)\n",
    "        seqs = seqs.unsqueeze(-1)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(seqs, seq_lengths.cpu(),\n",
    "                                                   batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
    "        z = torch.cat([num_x, cat_feat, h], dim=1)\n",
    "        z_cross = self.cross(z)\n",
    "        out = self.mlp(z_cross)\n",
    "        return out.squeeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kYtwWMrbEm5"
   },
   "source": [
    "### GDCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cXUOUN8c6u9"
   },
   "outputs": [],
   "source": [
    "\n",
    "from basic_layers import FeaturesEmbedding, MultiLayerPerceptron\n",
    "\n",
    "class GDCNModule(nn.Module):\n",
    "    def __init__(self, cat_cardinalities, emb_dim=16, cn_layers=3, mlp_layers=(400, 400, 400), dropout=0.5):\n",
    "        super().__init__()\n",
    "        # FeaturesEmbedding is assumed to be defined in models.basic_layers\n",
    "        self.embedding = FeaturesEmbedding(cat_cardinalities, emb_dim, concat=True)\n",
    "\n",
    "        if isinstance(emb_dim, int):\n",
    "            self.embed_output_dim = len(cat_cardinalities) * emb_dim\n",
    "        else:\n",
    "            self.embed_output_dim = sum(emb_dim)\n",
    "\n",
    "        self.cross_net = GateCorssLayer(self.embed_output_dim, cn_layers)\n",
    "        self.deep = MultiLayerPerceptron(self.embed_output_dim, mlp_layers, output_layer=False, dropout=dropout)\n",
    "        self.output_layer = nn.Linear(self.embed_output_dim + mlp_layers[-1], 1)\n",
    "\n",
    "    def forward(self, cat_x):\n",
    "        x_embed = self.embedding(cat_x)\n",
    "        cross_out = self.cross_net(x_embed)\n",
    "        deep_out = self.deep(x_embed)\n",
    "        out = self.output_layer(torch.cat([cross_out, deep_out], dim=1))\n",
    "        return out.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tYSJ3FrbJmU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class GDCNP(nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim, cn_layers=3, mlp_layers=(400, 400, 400), dropout=0.5):\n",
    "        super(GDCNP, self).__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim, concat=True)\n",
    "        # self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        if isinstance(embed_dim, int):\n",
    "            self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        else:\n",
    "            self.embed_output_dim = sum(embed_dim)\n",
    "        self.cross_net = GateCorssLayer(self.embed_output_dim, cn_layers)\n",
    "        self.mlp = MultiLayerPerceptron(self.embed_output_dim, mlp_layers, output_layer=False, dropout=dropout)\n",
    "        self.fc = torch.nn.Linear(mlp_layers[-1] + self.embed_output_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_emb = self.embedding(x)\n",
    "        # x_emb = self.embedding(x).view(-1, self.embed_output_dim)\n",
    "        cross_cn = self.cross_net(x_emb)\n",
    "        cross_mlp = self.mlp(x_emb)\n",
    "        pred_y = self.fc(torch.cat([cross_cn, cross_mlp], dim=1))\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "class GDCNS(torch.nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim, cn_layers=3, mlp_layers=(400, 400, 400), dropout=0.5):\n",
    "        super(GDCNS, self).__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim, concat=True)\n",
    "        if isinstance(embed_dim, int):\n",
    "            self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        else:\n",
    "            self.embed_output_dim = sum(embed_dim)\n",
    "        self.cross_net = GateCorssLayer(self.embed_output_dim, cn_layers)\n",
    "        self.pred_layer = MultiLayerPerceptron(self.embed_output_dim, mlp_layers, output_layer=True,\n",
    "                                               dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "        # x_embed = self.embedding(x).view(-1, self.embed_output_dim)\n",
    "        cross_cn = self.cross_net(x_embed)\n",
    "        pred_y = self.pred_layer(cross_cn)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "class GateCorssNetwork(torch.nn.Module):\n",
    "    def __init__(self, field_dims, embed_dim, cn_layers=3):\n",
    "        super(GateCorssNetwork, self).__init__()\n",
    "        self.embedding = FeaturesEmbedding(field_dims, embed_dim, concat=True)\n",
    "        if isinstance(embed_dim, int):\n",
    "            self.embed_output_dim = len(field_dims) * embed_dim\n",
    "        else:\n",
    "            self.embed_output_dim = sum(embed_dim)\n",
    "        self.cross_net = GateCorssLayer(self.embed_output_dim, cn_layers)\n",
    "        self.pred_layer = torch.nn.Linear(self.embed_output_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "        cross_cn = self.cross_net(x_embed)\n",
    "        pred_y = self.pred_layer(cross_cn)\n",
    "        return pred_y\n",
    "\n",
    "\n",
    "class GateCorssLayer(nn.Module):\n",
    "    #  The core structure： gated corss layer.\n",
    "    def __init__(self, input_dim, cn_layers=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cn_layers = cn_layers\n",
    "\n",
    "        self.w = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(input_dim, input_dim, bias=False) for _ in range(cn_layers)\n",
    "        ])\n",
    "        self.wg = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(input_dim, input_dim, bias=False) for _ in range(cn_layers)\n",
    "        ])\n",
    "\n",
    "        self.b = torch.nn.ParameterList([torch.nn.Parameter(\n",
    "            torch.zeros((input_dim,))) for _ in range(cn_layers)])\n",
    "\n",
    "        for i in range(cn_layers):\n",
    "            torch.nn.init.uniform_(self.b[i].data)\n",
    "\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = x\n",
    "        for i in range(self.cn_layers):\n",
    "            xw = self.w[i](x) # Feature Crossing\n",
    "            xg = self.activation(self.wg[i](x)) # Information Gate\n",
    "            x = x0 * (xw + self.b[i]) * xg + x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6BzdUfBZtw_"
   },
   "outputs": [],
   "source": [
    "class HybridGDCN(nn.Module):\n",
    "    def __init__(self, num_features, cat_cardinalities, emb_dim=16, lstm_hidden=64,\n",
    "                 cn_layers=3, mlp_layers=(400, 400, 400), dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = FeaturesEmbedding(cat_cardinalities, emb_dim, concat=True)\n",
    "        self.bn_num = nn.BatchNorm1d(num_features)\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden, num_layers=2,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "        if isinstance(emb_dim, int):\n",
    "            cat_feat_dim = len(cat_cardinalities) * emb_dim\n",
    "        else:\n",
    "            cat_feat_dim = sum(emb_dim)\n",
    "\n",
    "        self.seq_out_dim = lstm_hidden * 2\n",
    "        self.input_dim = cat_feat_dim + num_features + self.seq_out_dim\n",
    "\n",
    "        self.cross_net = GateCorssLayer(self.input_dim, cn_layers)\n",
    "        self.deep = MultiLayerPerceptron(self.input_dim, mlp_layers, output_layer=False, dropout=dropout)\n",
    "        self.output_layer = nn.Linear(self.input_dim + mlp_layers[-1], 1)\n",
    "\n",
    "    def forward(self, num_x, cat_x, seqs, seq_lengths):\n",
    "        num_x = self.bn_num(num_x)\n",
    "        cat_feat = self.embedding(cat_x)\n",
    "\n",
    "        seqs = seqs.unsqueeze(-1)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(seqs, seq_lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
    "\n",
    "        x = torch.cat([cat_feat, num_x, h], dim=1)\n",
    "        cross_out = self.cross_net(x)\n",
    "        deep_out = self.deep(x)\n",
    "        out = self.output_layer(torch.cat([cross_out, deep_out], dim=1))\n",
    "        return out.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1ECDSP_o8DV"
   },
   "source": [
    "## 5. TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X6zktYB9cXIe"
   },
   "outputs": [],
   "source": [
    "def train_model(train_df, num_cols, cat_cols, seq_col, target_col, batch_size, epochs, lr, device, model_type='wide_deep'):\n",
    "    train_dataset = ClickDataset(train_df, num_cols, cat_cols, seq_col, target_col, True)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              collate_fn=collate_fn_train, pin_memory=True)\n",
    "    cat_cardinalities = [len(cat_encoders[c].classes_) for c in cat_cols]\n",
    "\n",
    "    if model_type == 'gdcn':\n",
    "        model = GDCNModule(cat_cardinalities, emb_dim=16).to(device)\n",
    "    elif model_type == 'hybrid_gdcn':\n",
    "        model = HybridGDCN(num_features=len(num_cols),\n",
    "                           cat_cardinalities=cat_cardinalities,\n",
    "                           emb_dim=16).to(device)\n",
    "    else:\n",
    "        model = WideDeepCTR(num_features=len(num_cols),\n",
    "                            cat_cardinalities=cat_cardinalities,\n",
    "                            emb_dim=16).to(device)\n",
    "\n",
    "    pos_weight_value = (len(train_df) - train_df[target_col].sum()) / train_df[target_col].sum()\n",
    "    pos_weight = torch.tensor([pos_weight_value], dtype=torch.float).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=2, T_mult=2)\n",
    "\n",
    "    print(\"학습 시작\")\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"[Train Epoch {epoch}]\"):\n",
    "            if model_type == 'gdcn':\n",
    "                num_x, cat_x, seqs, lens, ys = batch\n",
    "                cat_x, ys = cat_x.to(device), ys.to(device)\n",
    "                logits = model(cat_x)\n",
    "            else:\n",
    "                num_x, cat_x, seqs, lens, ys = batch\n",
    "                num_x, cat_x, seqs, lens, ys = num_x.to(device), cat_x.to(device), seqs.to(device), lens.to(device), ys.to(device)\n",
    "                logits = model(num_x, cat_x, seqs, lens)\n",
    "\n",
    "            loss = criterion(logits, ys)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item() * ys.size(0)\n",
    "\n",
    "\n",
    "        total_loss /= len(train_dataset)\n",
    "        print(f\"[Epoch {epoch}] Train Loss: {total_loss:.4f}\")\n",
    "    print(\"학습 완료\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6633645,
     "status": "ok",
     "timestamp": 1758904284261,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "TkJ6qir0cd6S",
    "outputId": "8cfd789c-b282-4651-9e62-4f0870d22cae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 1]: 100%|██████████| 10454/10454 [21:59<00:00,  7.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 2]: 100%|██████████| 10454/10454 [21:35<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 1.2606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 3]: 100%|██████████| 10454/10454 [22:31<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 1.2549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 4]: 100%|██████████| 10454/10454 [22:09<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 1.2555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 5]: 100%|██████████| 10454/10454 [21:46<00:00,  8.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 1.2515\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "# model = train_model(\n",
    "#     train_df=train,\n",
    "#     num_cols=num_cols,\n",
    "#     cat_cols=cat_cols,\n",
    "#     seq_col=seq_col,\n",
    "#     target_col=target_col,\n",
    "#     batch_size=CFG['BATCH_SIZE'],\n",
    "#     epochs=CFG['EPOCHS'],\n",
    "#     lr=CFG['LEARNING_RATE'],\n",
    "#     device=device,\n",
    "#     model_type='gdcn'  # Options: 'gdcn', 'hybrid_gdcn', 'wide_deep'\n",
    "# )\n",
    "\n",
    "# public lb : 0.321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25695939,
     "status": "ok",
     "timestamp": 1758930254441,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "z9ksbWux4YPs",
    "outputId": "d3e60309-3ed3-4d43-d327-57b46686e70a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 1]: 100%|██████████| 10454/10454 [1:24:58<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 2]: 100%|██████████| 10454/10454 [1:25:50<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train Loss: 1.1859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 3]: 100%|██████████| 10454/10454 [1:25:38<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train Loss: 1.1633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 4]: 100%|██████████| 10454/10454 [1:25:22<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train Loss: 1.1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train Epoch 5]: 100%|██████████| 10454/10454 [1:26:03<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train Loss: 1.1504\n",
      "학습 완료\n"
     ]
    }
   ],
   "source": [
    "model = train_model(\n",
    "    train_df=train,\n",
    "    num_cols=num_cols,\n",
    "    cat_cols=cat_cols,\n",
    "    seq_col=seq_col,\n",
    "    target_col=target_col,\n",
    "    batch_size=CFG['BATCH_SIZE'],\n",
    "    epochs=CFG['EPOCHS'],\n",
    "    lr=CFG['LEARNING_RATE'],\n",
    "    device=device,\n",
    "    model_type='hybrid_gdcn'  # Options: 'gdcn', 'hybrid_gdcn', 'wide_deep'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1758930254573,
     "user": {
      "displayName": "구자협 (산업정보시스템전공)",
      "userId": "09674769247970950690"
     },
     "user_tz": -540
    },
    "id": "6d-En_JokROd",
    "outputId": "68b3ab0a-6768-4a91-f61f-852e17c7ab4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 저장 완료: 0926/model_hybrid_gdcn.pt\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('0926', exist_ok=True)\n",
    "save_path = 'model_hybrid_gdcn_5epoch.pt'\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"모델 저장 완료: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPatj8qEuuEg5pLvCX6i0dy",
   "gpuType": "A100",
   "mount_file_id": "18Okrwt-AVTpfyrrv575ps3RLpiuUneIW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
